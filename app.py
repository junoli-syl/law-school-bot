import streamlit as st
import google.generativeai as genai
import os

# ==========================================
# 1. é¡µé¢åŸºç¡€é…ç½® & è§†è§‰æ ·å¼ (Times New Roman)
# ==========================================
st.set_page_config(page_title="Juno Li's Law School AI Portfolio", layout="centered")

st.markdown(
    """
    <style>
    /* å¼ºåˆ¶æ‰€æœ‰å…ƒç´ ä½¿ç”¨ Times New Roman */
    * { font-family: "Times New Roman", Times, serif !important; }
    
    /* ä¾§è¾¹æ ç…§ç‰‡ï¼šåœ†å½¢ã€å±…ä¸­ã€å›ºå®šå¤§å° */
    [data-testid="stSidebar"] [data-testid="stImage"] img {
        border-radius: 50%;
        border: 2px solid #f0f2f6;
        width: 150px !important;
        height: 150px !important;
        object-fit: cover;
        margin: 0 auto;
        display: block;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ==========================================
# 2. æè‡´ç²¾ç®€çš„æ–‡ä»¶è¯»å– (åˆ©ç”¨ Session State æé€Ÿ)
# ==========================================
def load_context():
    c2025, c2022 = "", ""
    if os.path.exists("context"):
        for f_name in os.listdir("context"):
            if f_name.endswith(".txt"):
                with open(os.path.join("context", f_name), "r", encoding="utf-8") as f:
                    content = f.read()
                    if "_2025" in f_name:
                        c2025 += f"\n[PRIMARY 2025] {f_name}:\n{content}\n"
                    else:
                        c2022 += f"\n[SUPPLEMENTARY 2022] {f_name}:\n{content}\n"
    return c2025, c2022

if "grounding" not in st.session_state:
    st.session_state.grounding = load_context()

m2025, m2022 = st.session_state.grounding

# ==========================================
# 3. åˆå§‹åŒ–é€»è¾‘ (å®‰å…¨åŠ è½½)
# ==========================================
def initialize_agent():
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        
        # è·å–ç¼“å­˜çš„èµ„æ–™
        materials_2025, materials_2022 = get_prioritized_context()
        
        # è‡ªåŠ¨æ¢æµ‹æ¨¡å‹
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        target_model = "models/gemini-1.5-flash" if "models/gemini-1.5-flash" in models else models[0]

        system_instruction = f"""
        # ROLE: Digital Portfolio Agent for Juno Li (Law School Applicant).
        # HIERARCHY: Prioritize [PRIMARY SOURCE 2025] over [SUPPLEMENTARY EXAMPLE 2022].
        # PERSONA: Professional, Tech-Savvy, Humble, International Perspective. You are the "Digital Portfolio Agent" for Juno Li, an applicant to top-tier US law schools (T6). Your goal is to represent Juno's professional background, academic achievements, and personal motivations to Law School Admissions Officers.

        # GUARDRAILS
        1. **Missing Information:** If unknown, say "I don't have that specific detail, but based on Juno's background in tech...".
        2. **Privacy:** Do not reveal home address or phone number.
        
        # RESPONSE RULES:
        1. WORD LIMIT: Keep your responses around 250 words. Be concise but detailed enough for admissions officers.
        2. TONE: Use formal, analytical language (Times New Roman style thinking).
        
        # GROUNDING DATA:
        {materials_2025}
        {materials_2022}
        """

        model = genai.GenerativeModel(
            model_name=target_model,
            system_instruction=system_instruction,
            generation_config={"temperature": 0.1, "top_p": 0.95}
        )
        return model, target_model
    except Exception as e:
        st.error(f"Initialization Failed: {e}")
        return None, None

# ==========================================
# 4. æ‰§è¡Œåˆå§‹åŒ–å¹¶æ„å»ºä¾§è¾¹æ 
# ==========================================
model, active_model_name = initialize_agent()

with st.sidebar:
    # 1. åŠ å…¥ç…§ç‰‡
    if os.path.exists("juno_photo.jpg"):
        st.sidebar.image("juno_photo.jpg", use_container_width=True)
        
    st.title("Juno Li")
    st.caption("Technology Leader | JD Applicant")
    if active_model_name:
        st.success(f"âœ… Active: {active_model_name.replace('models/', '')}")
    
    st.markdown("---")
    st.markdown("### ğŸ”— Connect")
    st.link_button("LinkedIn Profile", "https://www.linkedin.com/in/juno-shunyu-li")
    st.link_button("Download Resume", "https://drive.google.com/file/d/16NSJE6s9_ZPOMMuZy3ObCd4L7u39er-B/view?usp=sharing")

# ==========================================
# 5. ä¸»ç•Œé¢æ¸²æŸ“ (ç¡®ä¿æ— è®ºå¦‚ä½•éƒ½ä¼šæ˜¾ç¤º)
# ==========================================
st.title("ğŸ‘©ğŸ»â€ğŸ’¼ Chat with Juno's AI")
st.markdown("""
**Your gateway to Junoâ€™s JD candidacy.** This AI agent provides instant insights into her **career transition**, **technical leadership at CVS/Aetna**, and **specific law school motivations**.
""")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Hello! I am Juno's digital law school representative. I'm here to help you navigate her professional background, academic achievements, and law school motivations. Feel free to ask anything, or use the quick-access buttons below to start."}]

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- å¿«é€Ÿæé—®æŒ‰é’® ---
def handle_click(prompt):
    st.session_state.clicked_prompt = prompt

col1, col2, col3 = st.columns(3)
with col1:
    st.button("Why Law?", on_click=handle_click, args=["Why do you want to go to law school given your tech career?"])
with col2:
    st.button("Tech Impact", on_click=handle_click, args=["Tell me about your technical leadership and its impact."])
with col3:
    st.button("Academic", on_click=handle_click, args=["Tell me about your academic background at GWU."])

# --- å¤„ç†ç”¨æˆ·è¾“å…¥ ---
user_input = st.chat_input("Ask about Juno's background...")

# æ£€æŸ¥æ˜¯å¦æœ‰æŒ‰é’®è¢«ç‚¹å‡»
if "clicked_prompt" in st.session_state:
    user_input = st.session_state.clicked_prompt
    del st.session_state.clicked_prompt

# æœ€åå¤„ç†è¾“å…¥å¹¶ç”Ÿæˆå›ç­”
if user_input:
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": user_input})
    # æ³¨æ„ï¼šä¸ºäº†è®©æŒ‰é’®ä¸æ¶ˆå¤±ï¼Œæˆ‘ä»¬é€šå¸¸éœ€è¦é€šè¿‡ st.rerun() 
    # æˆ–è€…ç¡®ä¿å¤„ç†é€»è¾‘åœ¨æ¸²æŸ“é€»è¾‘ä¹‹åã€‚
    # æœ€ç¨³å¦¥çš„æ–¹æ³•æ˜¯å¤„ç†å®Œåè®© Streamlit é‡æ–°è·‘ä¸€éè„šæœ¬ï¼ŒæŒ‰é’®è‡ªç„¶å°±å›æ¥äº†ã€‚
    
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        if model is None:
            st.error("AI is not ready.")
        else:
            with st.spinner("Generating response, it make take up to 2 minutes..."):
                try:
                    history = []
                    for m in st.session_state.messages[:-1]:
                        role = "model" if m["role"] == "assistant" else "user"
                        history.append({"role": role, "parts": [m["content"]]})
                    
                    chat = model.start_chat(history=history)
                    response = chat.send_message(user_input)
                    reply = response.text
                    st.session_state.messages.append({"role": "assistant", "content": reply})
                    
                    # å…³é”®ä¿®å¤ï¼šç”Ÿæˆå®Œå›ç­”åå¼ºåˆ¶åˆ·æ–°é¡µé¢ï¼Œè®©æŒ‰é’®é‡æ–°åœ¨ä¸‹æ–¹æ¸²æŸ“
                    st.rerun() 
                except Exception as e:
                    st.error(f"Chat Error: {e}")
